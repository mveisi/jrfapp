{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39d4f2ef-0c59-4523-9f68-3adcba63df54",
   "metadata": {},
   "source": [
    "# Jrfapp tutorial 4 \n",
    "## Inverting real dataset for station CHBR with PSO:\n",
    "\n",
    "First we need to import Initialize and Jrfapp_station. You can perform it by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c05e91ec-9482-428e-a4ca-1638605854bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jrfapp.main_classes import Initialize\n",
    "from jrfapp.main_classes import Jrfapp_station\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e779ffb-a6b5-476b-b838-d9d9c137ef3d",
   "metadata": {},
   "source": [
    "In this run we are going to use real dataset of CAD_P station in the joint inversion framework. The sac file provided\n",
    "in the station folder should have T0, Omarker, the USER4 must be ray parameter. We first need to create a Initialize object and refrence the data_folder and stations coordinate file. Similar to toturial 2, we can do it by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae4b2e6-2b08-4069-948d-4a9f83c94eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Folders that need to be defined:\n",
    "\n",
    "## Path to the data folder. This folder must contain your stations folder data. \n",
    "data_folder = '/mnt/4TB/soroush/CB_network'\n",
    "###############################################################################\n",
    "## Path to the folder which contains references models. The folder must only \n",
    "## contain .dat files. \n",
    "model_folder = '/home/soroush/my_py_rf/model_folder'\n",
    "###############################################################################\n",
    "## Path to the specific refrence initial model. These option used because you may want to\n",
    "## use different model as the reference model. \n",
    "model_name='/home/soroush/my_py_rf/model_folder/continent_tibet_model.dat'\n",
    "###############################################################################\n",
    "## Path to the coordinates file. This file must contain station name, lat and \n",
    "## long of the stations. Note that the station name in this file, the station \n",
    "## name in the data_folder and station name given to thr Jrfapp_station class \n",
    "## must be same.\n",
    "station_coordinate_file= '/home/soroush/my_py_rf/CB_coordinates'\n",
    "###############################################################################\n",
    "## The folder which package use for saving the output of stations. \n",
    "output_folder='/mnt/4TB/soroush/CB_st/syn_st'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "337fcbf5-4d7d-49b2-9279-4a89b3f27558",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_obj = Initialize(network_name='CB', \n",
    "                                    station_coordinate_file= station_coordinate_file,\n",
    "                                    data_folder= data_folder, \n",
    "                                    layering= [4, 5, 5], \n",
    "                                    model_folder = model_folder,\n",
    "                                    output_folder= output_folder, \n",
    "                                    model_name= model_name,\n",
    "                                    random_seed= 250)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef726077-119d-4756-ba27-4606f5b0a544",
   "metadata": {},
   "source": [
    "The makran_coordinates file contains the station name, latitude and longitude. \n",
    "for example \n",
    "> CHBR    25.595      60.482\n",
    "\n",
    "is one of the lines in makran_coordinates that correspond to CHBR station.\n",
    "\n",
    "The data_folder is where we saved the dataset of CHBR station. the data_folder structures must be as follow:\n",
    "> {data_folder}/{station_folder}/{event_folder}/*BHZ.SAC *BHE.SAC *BHN.SAC\n",
    "> data_folder/CHBR/2017119105924/2017119105924_BHE.SAC,\n",
    "> data_folder/CHBR/2017119105924/2017119105924_BHN.SAC,  \n",
    "> data_folder/CHBR/2017119105924/2017119105924_BHZ.SAC.\n",
    "\n",
    "Now we need to create Jrfapp_station with CHBR dataset. This can be done as follow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0932e48-00bc-4dcf-b6a6-a57d1c5e2ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating station CHBR \n",
      "found 1102 events from which \n",
      " 1090 had 3 waveforms\n",
      "reading files for network = MAKRAN ,station = CHBR\n",
      "all data saved for network= MAKRAN ,station= CHBR to:\n",
      "/home/soroush/rf_shallow_codes/makran_data/pkg_test_real_chbr_gs/MAKRAN_CHBR/MAKRAN_CHBR_all_data_bf_rf.bin\n",
      "preparing files for rf calculation for network = MAKRAN station = CHBR\n",
      "calculating RFs for network= MAKRAN, station= CHBR\n",
      "all rfs saved for network= MAKRAN ,station= CHBR to:\n",
      "/home/soroush/rf_shallow_codes/makran_data/pkg_test_real_chbr_gs/MAKRAN_CHBR/MAKRAN_CHBR_all_rf_gf_3.5.bin\n",
      "Start to stack in back azimuth bins before evaluating app vel, no of bins is: 24\n",
      "Start to stack in back azimuth bins after evaluating app vel, no of bins is: 24\n"
     ]
    }
   ],
   "source": [
    "jrfapp_stobj = Jrfapp_station(init_obj, name = 'CHBR')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe8e9d2-d921-49c8-b324-cc24253ae660",
   "metadata": {},
   "source": [
    "The backbone of Jrfapp_station is the Station_sor class. This class read the dataset, decimates and filters the data according to init_obj, and calculates RFs and Apparent velocities. Remove low-quality dataset, create several figures in output_folder/{station_name} folder, and prepare several stacks. \n",
    "These stacks are:\n",
    "#### 1. \"Linear Stack before app_vel criteria\":  \n",
    "> which is stacked RFs before\n",
    "> removing RFs that produce apparent velocities lower than \n",
    "> min_app_vel and greater than max_app_vel defined in the Initialize \n",
    "> class. I don't recommend using this because unrealistic values for \n",
    "> Apparent velocities are possibly generated by noise in the dataset.            \n",
    "#### 2. \"Linear Stack after app_vel criteria\", \n",
    "> which is stacked RFs before\n",
    "> removing RFs that produce apparent velocities lower than \n",
    "> min_app_vel and greater than max_app_vel defined in the Initialize \n",
    "> class. This is the recommended parameter for inversion. \n",
    "            \n",
    "#### 3. \"Phase Weighted stack after app_vel criteria\": \n",
    "> which is the phase \n",
    "> weighted stack of RFs after removing RFs which produce apparent\n",
    "> velocities lower than min_app_vel and greater than max_app_vel\n",
    "> defined in the Initialize class. I don't recommend using this\n",
    "> because moveout correction didn't apply to RFs in the phase \n",
    "> weighted stacking process and most of the multiple is removed \n",
    "> from RF time series.\n",
    "            \n",
    "#### 4. \"K0 Stack joint_harmonic before app_vel criteria\": \n",
    "> K0 stack is \n",
    "> based on removing first-order variation of azimuthal difference in \n",
    "> RFs. The basic idea is to keep the bulk value of each phase in the \n",
    "> RFR time series. However, this stacking method needs a reliable dataset\n",
    "> to constrain the azimuthal variation. This stack is the K0 stack before\n",
    "> removing RFs that produce apparent velocities lower than \n",
    "> min_app_vel and greater than max_app_vel defined in the Initialize \n",
    "> class. I don't recommend using this unless you have enough back azimuth\n",
    "> variation in a low-noise level dataset.\n",
    "            \n",
    "#### 5. \"K0 Stack joint_harmonic after app_vel criteria\": \n",
    "> like previous but\n",
    "> After removing RFs that produce apparent velocities lower than \n",
    "> min_app_vel and greater than max_app_vel defined in the Initialize \n",
    "> class. You can use this when you have a very good back azimuth \n",
    "> variation.\n",
    "           \n",
    "#### 6. \"Weighted Stack according to Number of trace in each bin before app_vel criteria\":\n",
    "> linear stack but weighted according to the\n",
    "> number of traces in each bin of back azimuth. In the process of \n",
    "> creating the Station the back azimuth is divided into 24 bins and RFs in \n",
    "> each bin are stacked. This stacking method uses the number of RFs in \n",
    "> each stack as the weight for stacking all 24 bins. This \n",
    "> stack calculated before removing RFs that produce apparent velocities\n",
    "> lower than min_app_vel and greater than max_app_vel defined in the\n",
    "> Initialize class. I don't recommend using this cause of noises that\n",
    "> produce unrealistic apparent velocity.\n",
    "            \n",
    "#### 8. \"Weighted Stack according to Number of trace in each bin after app_vel criteria\":\n",
    "> same as 6 but after removing RFs which \n",
    "> produce apparent velocities lower than min_app_vel and greater \n",
    "> than max_app_vel defined in the Initialize class. You can use this\n",
    "> when your RFs dominated by a specific back azimuth. \n",
    "            \n",
    "#### 10. \"Linear Stack of bins before app_vel criteria\": \n",
    "> same as 1 but \n",
    "            each bins have a weight equal to 1.\n",
    "\n",
    "#### 11. \"Linear Stack of bins after app_vel criteria\": \n",
    "> same as 8 but after \n",
    "> removing RFs that produce apparent velocities lower than min_app_vel \n",
    "> and greater than max_app_vel defined in the Initialize class.\n",
    "      \n",
    "#### 12. \"synthetic\":\n",
    "> for inverting synthetic data made from real datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d1344a-9db7-4329-bc96-09640e720067",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Tip:</b> It is good practice to save the jrfapp_stobj before performing inversion. you can do it as follow:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f8771a7-ea9d-4746-a31a-71e1e77a8661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to /home/soroush/rf_shallow_codes/makran_data/pkg_test_real_chbr_gs/real_data_chbr_gs\n"
     ]
    }
   ],
   "source": [
    "jrfapp_stobj_file_name = jrfapp_stobj.save_file(file_name='real_data_chbr_pso_bf_inv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ca6cd2-7862-491b-aeed-cf0a413ab59f",
   "metadata": {},
   "source": [
    "Now we invert the 'Linear Stack after app_vel criteria' which is the default stack for each station inversion. This\n",
    "can be done with either grid_search or PSO. For inversion using PSO, we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d915a1-8cc9-4d91-9782-4ad5b3027098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "dividing layers to 1\n",
      "Runing with initial smoothing and damping factors. \n",
      " smooth factor is :1.0 damp factor is : 0.5\n",
      "\n",
      "===============================================\n",
      "dividing layers to 1\n",
      "Runing with initial smoothing and damping factors. \n",
      " smooth factor is :1.0 damp factor is : 0.5\n",
      "===============================================\n",
      "dividing layers to 1\n",
      "Runing with initial smoothing and damping factors. \n",
      " smooth factor is :1.0 damp factor is : 0.5===============================================\n",
      "dividing layers to 1\n",
      "Runing with initial smoothing and damping factors. \n",
      " smooth factor is :1.0 damp factor is : 0.5\n",
      "===============================================\n",
      "dividing layers to 1\n",
      "Runing with initial smoothing and damping factors. \n",
      " smooth factor is :1.0 damp factor is : 0.5===============================================\n",
      "dividing layers to 1\n",
      "Runing with initial smoothing and damping factors. \n",
      " smooth factor is :1.0 damp factor is : 0.5\n",
      "\n",
      "===============================================\n",
      "dividing layers to 1\n",
      "Runing with increased smoothing and damping factors. \n",
      " smooth factor is :1.2 damp factor is : 0.55\n",
      "===============================================\n",
      "dividing layers to 1\n",
      "Runing with increased smoothing and damping factors. \n",
      " smooth factor is :1.2 damp factor is : 0.55\n",
      "===============================================\n",
      "dividing layers to 1\n",
      "Runing with increased smoothing and damping factors. \n",
      " smooth factor is :1.2 damp factor is : 0.55\n",
      "===============================================\n",
      "dividing layers to 1\n",
      "Runing with increased smoothing and damping factors. \n",
      " smooth factor is :1.2 damp factor is : 0.55\n",
      "===============================================\n",
      "dividing layers to 1\n",
      "Runing with increased smoothing and damping factors. \n",
      " smooth factor is :1.2 damp factor is : 0.55\n",
      "===============================================\n",
      "dividing layers to 1\n",
      "Runing with increased smoothing and damping factors. \n",
      " smooth factor is :1.2 damp factor is : 0.55\n",
      "===============================================\n",
      "dividing layers to 2\n",
      "Runing with initial smoothing and damping factors. \n",
      " smooth factor is :1.0 damp factor is : 0.5\n",
      "===============================================\n",
      "dividing layers to 2\n",
      "Runing with initial smoothing and damping factors. \n",
      " smooth factor is :1.0 damp factor is : 0.5\n",
      "===============================================\n",
      "dividing layers to 2\n",
      "Runing with initial smoothing and damping factors. \n",
      " smooth factor is :1.0 damp factor is : 0.5\n",
      "===============================================\n",
      "dividing layers to 2\n",
      "Runing with initial smoothing and damping factors. \n",
      " smooth factor is :1.0 damp factor is : 0.5\n",
      "===============================================\n",
      "dividing layers to 2\n",
      "Runing with initial smoothing and damping factors. \n",
      " smooth factor is :1.0 damp factor is : 0.5\n",
      "===============================================\n",
      "dividing layers to 2\n",
      "Runing with initial smoothing and damping factors. \n",
      " smooth factor is :1.0 damp factor is : 0.5\n",
      "===============================================\n",
      "dividing layers to 2\n",
      "Runing with increased smoothing and damping factors. \n",
      " smooth factor is :1.4 damp factor is : 0.6\n",
      "===============================================\n",
      "dividing layers to 2\n",
      "Runing with increased smoothing and damping factors. \n",
      " smooth factor is :1.4 damp factor is : 0.6\n",
      "===============================================\n",
      "dividing layers to 2\n",
      "Runing with increased smoothing and damping factors. \n",
      " smooth factor is :1.4 damp factor is : 0.6\n",
      "===============================================\n",
      "dividing layers to 2\n",
      "Runing with increased smoothing and damping factors. \n",
      " smooth factor is :1.4 damp factor is : 0.6\n",
      "===============================================\n",
      "dividing layers to 2\n",
      "Runing with increased smoothing and damping factors. \n",
      " smooth factor is :1.4 damp factor is : 0.6\n",
      "===============================================\n",
      "dividing layers to 2\n",
      "Runing with increased smoothing and damping factors. \n",
      " smooth factor is :1.4 damp factor is : 0.6\n",
      "===============================================\n",
      "dividing layers to 3\n",
      "Runing with initial smoothing and damping factors. \n",
      " smooth factor is :1.0 damp factor is : 0.5\n",
      "===============================================\n",
      "dividing layers to 3\n",
      "Runing with initial smoothing and damping factors. \n",
      " smooth factor is :1.0 damp factor is : 0.5\n",
      "===============================================\n",
      "dividing layers to 3\n",
      "Runing with initial smoothing and damping factors. \n",
      " smooth factor is :1.0 damp factor is : 0.5\n",
      "===============================================\n",
      "dividing layers to 3\n",
      "Runing with initial smoothing and damping factors. \n",
      " smooth factor is :1.0 damp factor is : 0.5\n",
      "===============================================\n",
      "dividing layers to 3\n",
      "Runing with initial smoothing and damping factors. \n",
      " smooth factor is :1.0 damp factor is : 0.5\n",
      "===============================================\n",
      "dividing layers to 3\n",
      "Runing with initial smoothing and damping factors. \n",
      " smooth factor is :1.0 damp factor is : 0.5\n",
      "===============================================\n",
      "dividing layers to 3\n",
      "Runing with increased smoothing and damping factors. \n",
      " smooth factor is :1.6 damp factor is : 0.65\n",
      "===============================================\n",
      "dividing layers to 3\n",
      "Runing with increased smoothing and damping factors. \n",
      " smooth factor is :1.6 damp factor is : 0.65\n",
      "===============================================\n",
      "dividing layers to 3\n",
      "Runing with increased smoothing and damping factors. \n",
      " smooth factor is :1.6 damp factor is : 0.65\n",
      "===============================================\n",
      "dividing layers to 3\n",
      "Runing with increased smoothing and damping factors. \n",
      " smooth factor is :1.6 damp factor is : 0.65\n",
      "===============================================\n",
      "dividing layers to 3\n",
      "Runing with increased smoothing and damping factors. \n",
      " smooth factor is :1.6 damp factor is : 0.65\n",
      "===============================================\n",
      "dividing layers to 3\n",
      "Runing with increased smoothing and damping factors. \n",
      " smooth factor is :1.6 damp factor is : 0.65\n",
      "===============================================\n",
      "dividing layers to 4\n",
      "Runing with initial smoothing and damping factors. \n",
      " smooth factor is :1.0 damp factor is : 0.5\n",
      "===============================================\n",
      "dividing layers to 4\n",
      "Runing with initial smoothing and damping factors. \n",
      " smooth factor is :1.0 damp factor is : 0.5\n",
      "===============================================\n",
      "dividing layers to 4\n",
      "Runing with initial smoothing and damping factors. \n",
      " smooth factor is :1.0 damp factor is : 0.5\n",
      "===============================================\n",
      "dividing layers to 4\n",
      "Runing with initial smoothing and damping factors. \n",
      " smooth factor is :1.0 damp factor is : 0.5\n",
      "===============================================\n",
      "dividing layers to 4\n",
      "Runing with initial smoothing and damping factors. \n",
      " smooth factor is :1.0 damp factor is : 0.5\n",
      "===============================================\n",
      "dividing layers to 4\n",
      "Runing with initial smoothing and damping factors. \n",
      " smooth factor is :1.0 damp factor is : 0.5\n"
     ]
    }
   ],
   "source": [
    "jrfapp_stobj.invert_data(inv_method = 'PSO',\n",
    "                stack_name = 'Linear Stack after app_vel criteria',\n",
    "                ndivide_list = [-1, 1, -2, 2, -3, 3, -4, 4], \n",
    "                PSO_nparticle = 2, PSO_maxiter = 2, \n",
    "                finer_ndivide= [-2, 2, -3, 3, -4, 4, -5, 5],\n",
    "                nthread = 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c79578-a646-4800-aca1-df9c57ac40b4",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Tip:</b> Again for simplicity i used 6 model in 6 thread.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc390708-82be-44a0-8d54-22a67f47b174",
   "metadata": {},
   "source": [
    "The inversion output figures saved into the '/home/soroush/rf_shallow_codes/makran_data/pkg_test_real_chbr_gs/{network_name}_{station_name}/{stack_name}/''\n",
    "\n",
    "These figures include the pseudo-initial model from PSO which is the model that generates the lowest difference between\n",
    "calculated and observed RFs and apparent velocities(the figure with subplots equal to the number of elements in finer_ndivide_list),  Output of mean shear velocity of interpolated PSO pseudo-initial models, and output of shear velocity models of PSO."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95581db2-05e7-4cfa-a5b1-e21b62b19678",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Tip:</b> We can save this station by:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf84f027-0745-42b1-b64a-334e593ccdbe",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'jrfapp_stobj' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m jrfapp_stobj_file_name \u001b[38;5;241m=\u001b[39m \u001b[43mjrfapp_stobj\u001b[49m\u001b[38;5;241m.\u001b[39msave_file(file_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreal_data_chbr_pso_bf_inv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'jrfapp_stobj' is not defined"
     ]
    }
   ],
   "source": [
    "jrfapp_stobj_file_name = jrfapp_stobj.save_file(file_name='real_data_chbr_pso_bf_inv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506b7ca0-3eda-4802-9d1d-8e5278b91421",
   "metadata": {},
   "source": [
    "#### The inversion output of jrfapp_stobj is saved as a dictionary in jrfapp_stobj.inv_info. \n",
    "#### The inv_info dictionary contains several keys. These keys are:\n",
    "\n",
    "1. all_iter:\n",
    "> This is a list containing inversion information of the pseudo-initial model either from PSO or grid_search for all divisions according to\n",
    "> to the finde_ndivide_list. Each inversion information for each iteration is a list that contains several parameters.\n",
    "> for example jrfapp_stobj.inv_info['all_iter'][0] represents the inversion of the pseudo-initial model with layers divided into 2.\n",
    "> This list contains these parameters:\n",
    "> first argument (jrfapp_stobj.inv_info['all_iter'][0][0]) is a list that represents the layer thickness of the model before inversion,\n",
    "> second argument (jrfapp_stobj.inv_info['all_iter'][0][1]) is a list that represents shear velocities before inversion.\n",
    "> third argument (jrfapp_stobj.inv_info['all_iter'][0][2]) is an array that represents shear velocity after inversion (estimated).\n",
    "> forth argument (jrfapp_stobj.inv_info['all_iter'][0][3]) is the norm of the difference between calculated and observed RFs after inversion.\n",
    "> fifth argument (jrfapp_stobj.inv_info['all_iter'][0][4]) is the norm of the difference between calculated and observed apparent velocity after inversion.\n",
    "> sixth argument (jrfapp_stobj.inv_info['all_iter'][0][5]) is calculated RFR.\n",
    "> seventh argument (jrfapp_stobj.inv_info['all_iter'][0][6]) is the calculated apparent velocity.\n",
    "> eighth argument (jrfapp_stobj.inv_info['all_iter'][0][7]) is the layer thickness after inversion (this is the layer thickness that you\n",
    "> should use for plotting shear velocities).\n",
    "\n",
    "2. best_inv:\n",
    "> This is a list that contains the best model (according to the lowest norm of the difference between calculated and observed RFs and apparent\n",
    "> velocities) from inversions with the different layering of the pseudo-initial model (best of all_iter).\n",
    "> The structures of this list are similar to those explained above(initial_layer_thickness, initial_shear_velocity,\n",
    "> estimated_shear_velocity, RF_norm, apparent_vel_norm, calculated_RFR, calculated_apparent_vel, estimated_layer_thickness).\n",
    "> This is a key that you want to show in your outputs.\n",
    "\n",
    "3. mean_vel_inv:\n",
    "> similar to 2, but for the mean velocity of grid_search (in case you used grid_search as an inversion method).\n",
    "\n",
    "4. name_pso:\n",
    "> path to the output of the PSO algorithm in case you want to use force_load in inversion, you can use this filename. only for PSO\n",
    ">  inversion method.\n",
    "\n",
    "5. vel_param:\n",
    "> Object of the velocity parameterization for the pseudo-initial model.\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1cb977-eb49-457e-b7ec-f67b35a86282",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
