{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a350767-cf3f-4842-859a-31600a094af7",
   "metadata": {},
   "source": [
    "## Jrfapp tutorial 2 \n",
    "## Inverting a synthetic Model using a real dataset with noise:\n",
    "\n",
    "First we need to import Initialize and Jrfapp_station. You can perform it by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "901b02a1-db66-49a5-9869-5e901ef78a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jrfapp.main_classes import Initialize\n",
    "from jrfapp.main_classes import Jrfapp_station\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb735753-8588-4a20-a267-43a5966c7651",
   "metadata": {},
   "source": [
    "In this run we want to read a real dataset from a station and perform a synthetic with 50.0 % noise level. \n",
    "The first step is to initialize the code. However, in this run we need to define the folder of our netwwork. This folder \n",
    "can contain several station data. Each station data is in a folder with a name according to an input file which define \n",
    "the station name and coordinates of all station of corresponding network. In this example i used the dataset of a permanent\n",
    "station in the MAKRAN network. We need to give the coordinates file name of this network in the Initialize class. The Initialize\n",
    "class is then defined as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a091e027-25f2-4841-b2a3-f933a5d93bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "## assigning folders and files needed for run.\n",
    "# first define the package folder you downloaded from git.\n",
    "package_folder = '/home/soroush/rf_shallow_codes/my_py_rf/Jrfapp_proj'\n",
    "station_coordinate_file_path = os.path.join(package_folder, 'makran_coordinates')\n",
    "data_folder_path = os.path.join(package_folder, 'makran_data')\n",
    "output_folder_path = os.path.join(package_folder, 'jrfapp_output_syn_wnoise')\n",
    "model_folder_path = os.path.join(package_folder, 'model_folder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9739bada-5826-4037-8e37-1b6f4dc612f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_obj = Initialize(network_name='MAKRAN', \n",
    "                               station_coordinate_file= station_coordinate_file_path,\n",
    "                               ,data_folder=data_folder_path, \n",
    "                               layering= [3, 4, 3], \n",
    "                  output_folder=output_folder_path, \n",
    "                   model_name= 'halfspace',\n",
    "                   random_seed= 250)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef11f42-dae2-4123-82f9-07493fd19755",
   "metadata": {},
   "source": [
    "The makran_coordinates file contains the station name, latitude and longitude. \n",
    "for example \n",
    "> CHBR    25.595      60.482\n",
    "\n",
    "is one of the lines in makran_coordinates that correspond to CHBR station.\n",
    "\n",
    "The data_folder is where we saved the dataset of CHBR station. the data_folder structures must be as follow:\n",
    "> {data_folder}/{station_folder}/{event_folder}/*BHZ.SAC *BHE.SAC *BHN.SAC\n",
    "> data_folder/CHBR/2017119105924/2017119105924_BHE.SAC,\n",
    "> data_folder/CHBR/2017119105924/2017119105924_BHN.SAC,  \n",
    "> data_folder/CHBR/2017119105924/2017119105924_BHZ.SAC.\n",
    "\n",
    "\n",
    "\n",
    "Now we need to define our synthetic model and Jrfapp_stobj for this station as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a06e437-20e7-475c-ae52-07d5339bea66",
   "metadata": {},
   "outputs": [],
   "source": [
    "which_to_pert = []\n",
    "which_to_pert.append([6, 12,  -0.6])\n",
    "which_to_pert.append([18, 24,  0.6])\n",
    "which_to_pert.append([30, 36, -0.6])\n",
    "which_to_pert.append([50, 60,  0.6])\n",
    "init_obj.create_synthetic(which_to_pert)\n",
    "jrfapp_stobj = cc.Jrfapp_station(init_obj, name = 'CHBR', \n",
    "                                      noise_level= 50.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb22a00-57dc-43f5-ae6d-4d6d5cb9af14",
   "metadata": {},
   "source": [
    "Next we can invert the data by either grid_search or PSO method. But first lets save the Jrfapp_stobj as the processes\n",
    "for calculating RF and Apparent velocity and stacking them can take long time and we dont want to repeat this processes \n",
    "every time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69881833-ea88-4b72-abc0-baf9d8686f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "jrfapp_stobj_file_name = jrfapp_stobj.save_file(file_name='syn_with_noise_gs_bf_inv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c955e09-8ecd-4e95-8b17-a4e9489ea4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "we can later load this data by pickle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c584d86-d86a-4bf1-b54a-f5ba9bbaf30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "jrfapp_stobj_file_name = '/home/soroush/rf_shallow_codes/my_py_rf/pkg_test_full_syn_chbr_gs/syn_with_noise_gs_bf_inv'\n",
    "with open(jrfapp_stobj_file_name, 'rb') as f1:\n",
    "    jrfapp_stobj = pickle.load(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7769a16-c0c8-4ba8-a24f-8d8127f8b907",
   "metadata": {},
   "source": [
    "Now we can invert synthetic data by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061eb953-56a3-423b-aa10-e2134702d441",
   "metadata": {},
   "outputs": [],
   "source": [
    "jrfapp_stobj.invert_data(inv_method = 'grid_search',\n",
    "                     stack_name = 'synthetic',\n",
    "                     ndivide_list = [-1, 1, -2, 2, -3, 3, -4, 4], \n",
    "                     nmodel = 6, nthread = 6, \n",
    "                     finer_ndivide= [-2, 2, -3, 3, -4, 4, -5, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a47fcee-bfa1-4f79-be0d-fd6db390fdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "jrfapp_stobj_file_name = jrfapp_stobj.save_file(file_name='syn_with_noise_gs_af_inv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d360e62-8253-4342-942b-e77d7ab10a21",
   "metadata": {},
   "source": [
    "Inversion using PSO:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5909841-fe44-4fd1-8b6b-e95ea6cdd4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "jrfapp_stobj.invert_data(inv_method = 'PSO',\n",
    "                stack_name = 'synthetic',\n",
    "                ndivide_list = [-1, 1, -2, 2, -3, 3, -4, 4], \n",
    "                PSO_nparticle = 4, PSO_maxiter = 2, \n",
    "                nthread = 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4573e5cc-839a-41ba-ae02-2008605b0c0c",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Tip:</b> Again for simplicity I run the inversion with 6 models for grid_search and 4 particles in 2 iterations for the PSO run.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ef0788-2df8-455c-8646-cf132aceffb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
